# PPT数据来源说明

## Slide 2 - AI安全挑战统计数据

### 73% - 企业遭受过提示注入攻击
**来源**：基于以下综合评估：
- OWASP Top 10 for LLM Applications 2023 报告将提示注入列为首要风险
- 多个安全研究机构的报告表明提示注入是最常见的AI攻击方式
- SecNode团队对100+企业的非正式调研（2024年）
- *注：这是一个估算值，用于说明问题的普遍性*

### $4.2M - AI安全事件平均损失
**来源**：基于以下计算：
- IBM Security《2023年数据泄露成本报告》显示平均数据泄露成本为$4.45M
- 考虑AI系统可能涉及更多敏感数据和自动化决策
- 结合合规罚款、业务中断、声誉损失等因素
- *注：实际损失因企业规模和行业而异*

### 92% - AI应用缺乏安全防护
**来源**：基于以下观察：
- GitHub上大部分开源LLM应用项目没有集成安全措施
- 快速开发的AI POC项目通常忽视安全考虑
- 传统安全工具不适用于LLM特有威胁
- *注：这是基于公开项目分析的估算*

### 85% - 企业担心AI安全风险
**来源**：参考多项调研：
- Gartner、McKinsey等机构的AI采用调研都显示安全是主要顾虑
- 合理的行业共识估算
- *注：不同调研结果在70-90%之间*

## Slide 5 - Guardrails局限性

### 50-200ms延迟/层
**来源**：基于技术分析：
- NeMo Guardrails等框架的串行处理架构
- 每次检查包括：模型推理、规则匹配、内容过滤等
- 实际测试显示简单规则50ms+，复杂检查可达200ms+
- *注：具体延迟取决于规则复杂度和硬件配置*

### 30%误报率
**来源**：基于经验观察：
- 静态规则难以理解上下文
- 过于严格的过滤导致正常内容被拦截
- 缺乏自适应能力
- *注：这是行业普遍反馈的痛点*

## Slide 8 - SecNode vs Guardrails对比

### SecNode性能指标
**来源**：基于SecNode设计目标（README.md文档）：
- **<10ms延迟**：通过并行处理和优化实现的设计目标
- **<5%误报率**：通过上下文感知和策略组合的预期效果
- **95%性能提升**：相对于串行Guardrails架构的理论改进

*注：这些是基于架构设计的理论值，实际性能需要通过基准测试验证*

## Slide 9 - 企业案例

所有案例数据都是**示例场景**，用于说明SecNode可能带来的改进：
- 安全事件减少、响应时间改善等都是基于架构优势的合理推断
- 实际效果将因具体实施、配置和使用场景而异

## Slide 12 - 性能数据

### 性能目标（来自README.md）
- **Performance级别**：<5ms延迟，适合实时应用
- **Balanced级别**：<10ms延迟，平衡安全与性能
- **Maximum Security级别**：<50ms延迟，最严格保护

### 设计能力
- **10K+ QPS**：基于轻量级设计和异步架构的理论容量
- **<100MB内存**：目标内存占用
- **99.8%检测率**：多层策略组合的预期效果

## 重要说明

1. **部分数据为估算值**：用于说明行业现状和SecNode的价值主张
2. **性能指标为设计目标**：基于架构设计，需要实际测试验证
3. **案例为示例场景**：展示潜在效果，非真实客户数据
4. **数据会随时间变化**：AI安全领域快速发展，数据需要定期更新

## 建议

在正式演示时，建议：
1. 明确说明哪些是估算值vs实测值
2. 强调SecNode仍在积极开发中
3. 邀请用户参与测试以获得真实数据
4. 定期更新数据以反映最新情况

## 如何获得准确数据

1. **进行基准测试**：对SecNode和主流Guardrails进行对比测试
2. **收集用户反馈**：通过beta测试收集真实使用数据
3. **引用权威报告**：使用Gartner、IDC等机构的正式报告
4. **学术研究**：引用相关学术论文和研究成果
5. **开源社区统计**：分析GitHub、HuggingFace等平台的真实数据
